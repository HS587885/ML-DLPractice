# 과대 적합(Overfitting)

![image](https://user-images.githubusercontent.com/80622859/225609310-ef7e0464-ac5c-4ece-916e-a9760e56a7d5.png)

- 마치 시험 족보를 외우듯이 주어진 문제의 답을 암기해버리는 것 
- 일반적인 특성을 확인 불가

# Dataset

- Training data(50%~70%) : 학습 과정에 보여지고, 실제 모형을 학습하는데 사용
- Validation data(5%~15%) : 학습 과정에 보여지지만, 모형 학습에 사용하지 않고 학습이 잘 되는지 검증하는데 사용
- Test data(30%~50%) : 학습 과정에서는 사용하지 않고, 학습을 마친 모형을 평가하기 위해 단 한 번만 사용
- 과적합을 막기 위해서 위처럼 나누는 것이 중요
- Training data에 대해서는 성능이 잘 나오나 validation data에서 성능이 안 좋을 시 과적합
- Training loop : Training set + Validation set

# 손실 함수 

![image](https://user-images.githubusercontent.com/80622859/225610425-75a8dc98-932d-4ca5-9bc9-b214cf23ba38.png)

# 해결 방법

## 조기 종료(Early stopping)

![image](https://user-images.githubusercontent.com/80622859/225610671-cd25e022-4061-424a-9051-301557be7d60.png)

- 검증 손실이 여러 epoch 동안 감소하지 않으면 과적합으로 간주하여 학습 중단
- 유예(patience)를 두고 봄

## Drop out

![image](https://user-images.githubusercontent.com/80622859/225610952-9910b30b-2a58-4211-b848-37c9bf97770d.png)

- 지정한 비율의 node를 제거하고 학습하는 방법
- Test 시에는 모든 node를 사용하기 때문에, 여러 신경망을 ensemble한 효과를 가짐

## Batch normalization

![image](https://user-images.githubusercontent.com/80622859/225611382-b55e7b1b-4768-4978-95d8-ac63e723d72c.png)

- 중간 feature들을 그대로 사용하지 않고 변형하여 학습 
