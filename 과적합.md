# 과대 적합(Overfitting)

![image](https://user-images.githubusercontent.com/80622859/225609310-ef7e0464-ac5c-4ece-916e-a9760e56a7d5.png)

- 마치 시험 족보를 외우듯이 주어진 문제의 답을 암기해버리는 것 
- 일반적인 특성을 확인 불가
- 검증 손실과 학습 손실 차이가 많이 나게 됨

# Dataset

- Training data(50%~70%) : 학습 과정에 보여지고, 실제 모형을 학습하는데 사용
- Validation data(5%~15%) : 학습 과정에 보여지지만, 모형 학습에 사용하지 않고 학습이 잘 되는지 검증하는데 사용
- Test data(30%~50%) : 학습 과정에서는 사용하지 않고, 학습을 마친 모형을 평가하기 위해 단 한 번만 사용
- 과적합을 막기 위해서 위처럼 나누는 것이 중요
- Training data에 대해서는 성능이 잘 나오나 validation data에서 성능이 안 좋을 시 과적합
- Training loop : Training set + Validation set

# 손실 함수 

![image](https://user-images.githubusercontent.com/80622859/225610425-75a8dc98-932d-4ca5-9bc9-b214cf23ba38.png)

- $Cost = Loss(Data|Model) + \lambda Complexity(Model)$
- 손실에 집중 : Training data에 대한 신뢰도가 높음. Training data에 속하지 않은 입력에 취약
- 복잡도를 낮춤 : 모형의 복잡도가 지나치게 높아지지 않도록 제약. Data training보다 일반화에 투자
- 

# 해결 방법

## 조기 종료(Early stopping)

![image](https://user-images.githubusercontent.com/80622859/225610671-cd25e022-4061-424a-9051-301557be7d60.png)

- 검증 손실이 여러 epoch 동안 감소하지 않으면 과적합으로 간주하여 학습 중단
- 유예(patience)를 두고 봄

## Drop out

![image](https://user-images.githubusercontent.com/80622859/225610952-9910b30b-2a58-4211-b848-37c9bf97770d.png)

- 지정한 비율의 node를 제거하고 학습하는 방법
- Test 시에는 모든 node를 사용하기 때문에, 여러 신경망을 ensemble한 효과를 가짐

## Batch normalization

![image](https://user-images.githubusercontent.com/80622859/225611382-b55e7b1b-4768-4978-95d8-ac63e723d72c.png)

- 중간 feature들을 그대로 사용하지 않고 변형하여 학습 

## L-2 Regularization

- $Complexity(Model) = \frac{1}{N}\sum_i \frac{1}{2} w^2_i = \frac{1}{2} ||w||^2$
- 아주 큰 가중치에 penalty
- 구불구불한 것보다 평평한 형태 선호
- Bayses' prior probability distribution(정규 분포)
- Ridge
- 가중치가 정규분포의 형태를 이루도록 함
- 
