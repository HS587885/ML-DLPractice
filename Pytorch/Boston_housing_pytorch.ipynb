{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/as9786/ML-DLPratice/blob/main/Pytorch/Boston_housing_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "-xUf1Mf6NhbE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYb85NcrM8V4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, train_targets), (test_data, test_targets) = keras.datasets.boston_housing.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3rOKjwRNbjb",
        "outputId": "89f4698e-2ff1-4a0e-d206-dc80b74e8709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module"
      ],
      "metadata": {
        "id": "kGCTzZe4NjUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XRITPkWSNcOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_targets))\n",
        "print(len(test_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yit4d0dlPbCF",
        "outputId": "1005464d-5700-401c-950f-80ef5905340c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404\n",
            "102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(train_data) + list(test_data)\n",
        "target = list(train_targets) + list(test_targets)\n",
        "len(data), len(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHMRAygGPqhb",
        "outputId": "d9788d86-978f-4f6b-97b2-fc5165843e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 506)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "target = np.array(target)"
      ],
      "metadata": {
        "id": "DzEVVCb3RlYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(data,target,test_size=0.3)\n",
        "X_valid,X_test,y_valid,y_test = train_test_split(X_valid,y_valid,test_size=0.35)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_valid))\n",
        "print(len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiuThz9TQJIl",
        "outputId": "188b9e4f-7207-44e4-f7b8-a9a8a84b86a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354\n",
            "98\n",
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)\n",
        "type(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcokJvj5Refb",
        "outputId": "478d27af-4c6e-4bb1-de9d-617dc7195f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJlgZksDR-PJ",
        "outputId": "e826aa27-c492-4a4e-f285-f55064dd10f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(354,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch dataset"
      ],
      "metadata": {
        "id": "H0TmTCWfOWuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "cjkL2i3RSnZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BostonDataset(Dataset):\n",
        "    scaler = StandardScaler()\n",
        "    def __init__(self,X,y,phase):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        if phase == 'train':\n",
        "            self.X = BostonDataset.scaler.fit_transform(self.X)\n",
        "        else:\n",
        "            self.X = BostonDataset.scaler.transform(self.X)\n",
        "\n",
        "    def __len__(self): \n",
        "        assert len(self.X) == len(self.y)\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self,idx): \n",
        "        data = torch.tensor(self.X[idx],dtype=torch.float)\n",
        "        price = torch.tensor(self.y[idx],dtype=torch.float)\n",
        "        # data = self.X[idx]\n",
        "        # price = self.y[idx]\n",
        "        return data, price"
      ],
      "metadata": {
        "id": "OyjKb4xvNfeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BostonDataset(X_train,y_train,'train') \n",
        "valid_dataset = BostonDataset(X_valid,y_valid,'valid')\n",
        "test_dataset = BostonDataset(X_test,y_test,'test')"
      ],
      "metadata": {
        "id": "xOr4BlEJO4By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset,batch_size=16) \n",
        "test_loader = DataLoader(test_dataset,batch_size=1)"
      ],
      "metadata": {
        "id": "wXnpW81QQ-u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_loader:\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvjBo9EaRMan",
        "outputId": "9fb2c8eb-2b16-4d1a-f5f9-aad66d15a1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 13])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "lxgbtwFUSVjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weight_init = nn.init.xavier_uniform_\n",
        "        self.linear1 = nn.Linear(13,64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(64,64)\n",
        "        self.linear3 = nn.Linear(64,1)\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self.weight_init(self.linear1.weight)\n",
        "        self.weight_init(self.linear2.weight)\n",
        "        self.weight_init(self.linear3.weight)\n",
        "        \n",
        "\n",
        "    def forward(self,x):\n",
        "        h1 = self.linear1(x)\n",
        "        h1 = self.relu(h1)\n",
        "        h2 = self.linear2(h1)\n",
        "        h2 = self.relu(h2)\n",
        "        output = self.linear3(h2)\n",
        "        return output"
      ],
      "metadata": {
        "id": "WBg-0IBtRU3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOey-pKnXICD",
        "outputId": "3da84bbe-8e0b-4405-8e01-445e218e8210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "7O2C7Fg4XNPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPRegressor()"
      ],
      "metadata": {
        "id": "cacGIm0oT_p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8tNp4HBXOsX",
        "outputId": "96e1c746-0b8a-4a5d-bb6f-41d46d5b2c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(\n",
              "  (linear1): Linear(in_features=13, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnfNA6t-iDa3",
        "outputId": "f4e32cbb-6c4a-469c-e974-47d5c91d1408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgCYEuJGV2YE",
        "outputId": "7e45f382-0b7d-47c7-e25b-343356a5a59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "MLPRegressor                             --\n",
              "├─Linear: 1-1                            896\n",
              "├─ReLU: 1-2                              --\n",
              "├─Linear: 1-3                            4,160\n",
              "├─Linear: 1-4                            65\n",
              "=================================================================\n",
              "Total params: 5,121\n",
              "Trainable params: 5,121\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "#loss_fn = nn.functional.mse_loss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "hAy6yE-bV9we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader,model,loss_fn,optimizer,epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X,y) in enumerate(dataloader): \n",
        "        X,y = X.to(device), y.to(device)\n",
        "        # 예측과 손실 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred,y)\n",
        "\n",
        "        #역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f'loss : {loss:>7f}, [{current:>5d}/{size:>5d}]')\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "6wumHjVeWVES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0,0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X,y in dataloader:\n",
        "            X,y = X.to(device), y.to(device) \n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred,y).item()\n",
        "            \n",
        "        test_loss /= num_batches\n",
        "        print(f'Test loss : {test_loss:>8f}')\n",
        "\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "i3JesND0Xse-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 진행하기\n",
        "epochs = 100\n",
        "losses = []\n",
        "val_losses = []\n",
        "for t in range(epochs):\n",
        "    print(f'Epoch {t+1}\\n----------------')\n",
        "    epoch_loss = train(train_loader,model,loss_fn,optimizer)\n",
        "    losses.append(epoch_loss)\n",
        "    epoch_test_loss = test(valid_loader,model,loss_fn) \n",
        "    val_losses.append(epoch_test_loss)\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow5n5887hnou",
        "outputId": "4dd9c206-0a57-479a-9dc6-9925f072a4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "----------------\n",
            "loss : 77.105583, [    0/  354]\n",
            "loss : 90.300621, [  320/  354]\n",
            "Test loss : 82.365346\n",
            "Epoch 2\n",
            "----------------\n",
            "loss : 58.153095, [    0/  354]\n",
            "loss : 51.238708, [  320/  354]\n",
            "Test loss : 82.374218\n",
            "Epoch 3\n",
            "----------------\n",
            "loss : 41.077034, [    0/  354]\n",
            "loss : 61.544395, [  320/  354]\n",
            "Test loss : 82.506145\n",
            "Epoch 4\n",
            "----------------\n",
            "loss : 70.159050, [    0/  354]\n",
            "loss : 82.990807, [  320/  354]\n",
            "Test loss : 83.152569\n",
            "Epoch 5\n",
            "----------------\n",
            "loss : 98.800766, [    0/  354]\n",
            "loss : 59.225609, [  320/  354]\n",
            "Test loss : 82.020861\n",
            "Epoch 6\n",
            "----------------\n",
            "loss : 68.982254, [    0/  354]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-149-f1e096a247c1>:7: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = loss_fn(pred,y)\n",
            "<ipython-input-149-f1e096a247c1>:7: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = loss_fn(pred,y)\n",
            "<ipython-input-150-72c2c018714e>:10: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  test_loss += loss_fn(pred,y).item()\n",
            "<ipython-input-150-72c2c018714e>:10: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  test_loss += loss_fn(pred,y).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 96.145859, [  320/  354]\n",
            "Test loss : 81.919078\n",
            "Epoch 7\n",
            "----------------\n",
            "loss : 92.891098, [    0/  354]\n",
            "loss : 55.092369, [  320/  354]\n",
            "Test loss : 81.981549\n",
            "Epoch 8\n",
            "----------------\n",
            "loss : 115.138794, [    0/  354]\n",
            "loss : 120.902184, [  320/  354]\n",
            "Test loss : 82.297915\n",
            "Epoch 9\n",
            "----------------\n",
            "loss : 119.197693, [    0/  354]\n",
            "loss : 50.405205, [  320/  354]\n",
            "Test loss : 82.134651\n",
            "Epoch 10\n",
            "----------------\n",
            "loss : 57.639309, [    0/  354]\n",
            "loss : 87.382996, [  320/  354]\n",
            "Test loss : 82.047802\n",
            "Epoch 11\n",
            "----------------\n",
            "loss : 63.174866, [    0/  354]\n",
            "loss : 81.513504, [  320/  354]\n",
            "Test loss : 81.735810\n",
            "Epoch 12\n",
            "----------------\n",
            "loss : 79.941368, [    0/  354]\n",
            "loss : 96.251282, [  320/  354]\n",
            "Test loss : 81.660670\n",
            "Epoch 13\n",
            "----------------\n",
            "loss : 76.610085, [    0/  354]\n",
            "loss : 103.047142, [  320/  354]\n",
            "Test loss : 81.769600\n",
            "Epoch 14\n",
            "----------------\n",
            "loss : 108.713554, [    0/  354]\n",
            "loss : 45.312294, [  320/  354]\n",
            "Test loss : 81.756896\n",
            "Epoch 15\n",
            "----------------\n",
            "loss : 71.503052, [    0/  354]\n",
            "loss : 89.972412, [  320/  354]\n",
            "Test loss : 81.864278\n",
            "Epoch 16\n",
            "----------------\n",
            "loss : 59.254044, [    0/  354]\n",
            "loss : 84.053070, [  320/  354]\n",
            "Test loss : 81.403155\n",
            "Epoch 17\n",
            "----------------\n",
            "loss : 76.421112, [    0/  354]\n",
            "loss : 88.806244, [  320/  354]\n",
            "Test loss : 83.696273\n",
            "Epoch 18\n",
            "----------------\n",
            "loss : 82.687744, [    0/  354]\n",
            "loss : 91.763977, [  320/  354]\n",
            "Test loss : 81.088599\n",
            "Epoch 19\n",
            "----------------\n",
            "loss : 101.857994, [    0/  354]\n",
            "loss : 105.317108, [  320/  354]\n",
            "Test loss : 80.993340\n",
            "Epoch 20\n",
            "----------------\n",
            "loss : 77.590935, [    0/  354]\n",
            "loss : 83.297272, [  320/  354]\n",
            "Test loss : 81.389069\n",
            "Epoch 21\n",
            "----------------\n",
            "loss : 38.662907, [    0/  354]\n",
            "loss : 67.293503, [  320/  354]\n",
            "Test loss : 80.991858\n",
            "Epoch 22\n",
            "----------------\n",
            "loss : 42.198624, [    0/  354]\n",
            "loss : 125.368111, [  320/  354]\n",
            "Test loss : 81.126408\n",
            "Epoch 23\n",
            "----------------\n",
            "loss : 69.058182, [    0/  354]\n",
            "loss : 95.993729, [  320/  354]\n",
            "Test loss : 81.043376\n",
            "Epoch 24\n",
            "----------------\n",
            "loss : 55.079147, [    0/  354]\n",
            "loss : 34.917381, [  320/  354]\n",
            "Test loss : 81.289778\n",
            "Epoch 25\n",
            "----------------\n",
            "loss : 82.416771, [    0/  354]\n",
            "loss : 67.151459, [  320/  354]\n",
            "Test loss : 81.291102\n",
            "Epoch 26\n",
            "----------------\n",
            "loss : 92.841019, [    0/  354]\n",
            "loss : 75.308304, [  320/  354]\n",
            "Test loss : 81.728488\n",
            "Epoch 27\n",
            "----------------\n",
            "loss : 21.845648, [    0/  354]\n",
            "loss : 106.304985, [  320/  354]\n",
            "Test loss : 81.700806\n",
            "Epoch 28\n",
            "----------------\n",
            "loss : 67.965225, [    0/  354]\n",
            "loss : 97.171829, [  320/  354]\n",
            "Test loss : 81.886123\n",
            "Epoch 29\n",
            "----------------\n",
            "loss : 57.265659, [    0/  354]\n",
            "loss : 79.671341, [  320/  354]\n",
            "Test loss : 81.783927\n",
            "Epoch 30\n",
            "----------------\n",
            "loss : 67.744965, [    0/  354]\n",
            "loss : 47.720612, [  320/  354]\n",
            "Test loss : 81.802516\n",
            "Epoch 31\n",
            "----------------\n",
            "loss : 71.124863, [    0/  354]\n",
            "loss : 125.373070, [  320/  354]\n",
            "Test loss : 81.653466\n",
            "Epoch 32\n",
            "----------------\n",
            "loss : 59.889969, [    0/  354]\n",
            "loss : 75.610207, [  320/  354]\n",
            "Test loss : 81.632013\n",
            "Epoch 33\n",
            "----------------\n",
            "loss : 29.017410, [    0/  354]\n",
            "loss : 83.106522, [  320/  354]\n",
            "Test loss : 81.779070\n",
            "Epoch 34\n",
            "----------------\n",
            "loss : 55.209518, [    0/  354]\n",
            "loss : 101.805405, [  320/  354]\n",
            "Test loss : 82.081582\n",
            "Epoch 35\n",
            "----------------\n",
            "loss : 57.967068, [    0/  354]\n",
            "loss : 28.375639, [  320/  354]\n",
            "Test loss : 82.124434\n",
            "Epoch 36\n",
            "----------------\n",
            "loss : 63.788380, [    0/  354]\n",
            "loss : 127.261459, [  320/  354]\n",
            "Test loss : 82.318159\n",
            "Epoch 37\n",
            "----------------\n",
            "loss : 89.900970, [    0/  354]\n",
            "loss : 133.431183, [  320/  354]\n",
            "Test loss : 83.221798\n",
            "Epoch 38\n",
            "----------------\n",
            "loss : 123.102768, [    0/  354]\n",
            "loss : 33.743904, [  320/  354]\n",
            "Test loss : 83.383027\n",
            "Epoch 39\n",
            "----------------\n",
            "loss : 69.067192, [    0/  354]\n",
            "loss : 122.393593, [  320/  354]\n",
            "Test loss : 84.087885\n",
            "Epoch 40\n",
            "----------------\n",
            "loss : 68.795547, [    0/  354]\n",
            "loss : 104.020981, [  320/  354]\n",
            "Test loss : 82.714123\n",
            "Epoch 41\n",
            "----------------\n",
            "loss : 49.032703, [    0/  354]\n",
            "loss : 81.552536, [  320/  354]\n",
            "Test loss : 82.849074\n",
            "Epoch 42\n",
            "----------------\n",
            "loss : 73.827782, [    0/  354]\n",
            "loss : 78.701508, [  320/  354]\n",
            "Test loss : 82.754461\n",
            "Epoch 43\n",
            "----------------\n",
            "loss : 25.556843, [    0/  354]\n",
            "loss : 100.086647, [  320/  354]\n",
            "Test loss : 82.593643\n",
            "Epoch 44\n",
            "----------------\n",
            "loss : 67.294449, [    0/  354]\n",
            "loss : 74.673630, [  320/  354]\n",
            "Test loss : 82.416227\n",
            "Epoch 45\n",
            "----------------\n",
            "loss : 98.542267, [    0/  354]\n",
            "loss : 58.562298, [  320/  354]\n",
            "Test loss : 82.951358\n",
            "Epoch 46\n",
            "----------------\n",
            "loss : 112.504807, [    0/  354]\n",
            "loss : 84.539139, [  320/  354]\n",
            "Test loss : 81.872733\n",
            "Epoch 47\n",
            "----------------\n",
            "loss : 111.516342, [    0/  354]\n",
            "loss : 95.164841, [  320/  354]\n",
            "Test loss : 81.972097\n",
            "Epoch 48\n",
            "----------------\n",
            "loss : 57.512970, [    0/  354]\n",
            "loss : 54.790016, [  320/  354]\n",
            "Test loss : 82.099063\n",
            "Epoch 49\n",
            "----------------\n",
            "loss : 101.147362, [    0/  354]\n",
            "loss : 65.620209, [  320/  354]\n",
            "Test loss : 82.078165\n",
            "Epoch 50\n",
            "----------------\n",
            "loss : 40.336422, [    0/  354]\n",
            "loss : 113.819595, [  320/  354]\n",
            "Test loss : 82.258490\n",
            "Epoch 51\n",
            "----------------\n",
            "loss : 127.433113, [    0/  354]\n",
            "loss : 90.975052, [  320/  354]\n",
            "Test loss : 81.893546\n",
            "Epoch 52\n",
            "----------------\n",
            "loss : 87.148064, [    0/  354]\n",
            "loss : 59.828014, [  320/  354]\n",
            "Test loss : 81.999142\n",
            "Epoch 53\n",
            "----------------\n",
            "loss : 69.221176, [    0/  354]\n",
            "loss : 71.645416, [  320/  354]\n",
            "Test loss : 82.050739\n",
            "Epoch 54\n",
            "----------------\n",
            "loss : 119.677612, [    0/  354]\n",
            "loss : 115.753914, [  320/  354]\n",
            "Test loss : 82.263642\n",
            "Epoch 55\n",
            "----------------\n",
            "loss : 61.945229, [    0/  354]\n",
            "loss : 104.119690, [  320/  354]\n",
            "Test loss : 82.412607\n",
            "Epoch 56\n",
            "----------------\n",
            "loss : 106.984207, [    0/  354]\n",
            "loss : 65.699287, [  320/  354]\n",
            "Test loss : 82.270238\n",
            "Epoch 57\n",
            "----------------\n",
            "loss : 146.325348, [    0/  354]\n",
            "loss : 63.518017, [  320/  354]\n",
            "Test loss : 82.139892\n",
            "Epoch 58\n",
            "----------------\n",
            "loss : 104.201767, [    0/  354]\n",
            "loss : 73.126259, [  320/  354]\n",
            "Test loss : 82.520993\n",
            "Epoch 59\n",
            "----------------\n",
            "loss : 93.634995, [    0/  354]\n",
            "loss : 68.145912, [  320/  354]\n",
            "Test loss : 83.432987\n",
            "Epoch 60\n",
            "----------------\n",
            "loss : 64.695015, [    0/  354]\n",
            "loss : 47.663559, [  320/  354]\n",
            "Test loss : 82.611863\n",
            "Epoch 61\n",
            "----------------\n",
            "loss : 72.435310, [    0/  354]\n",
            "loss : 108.933182, [  320/  354]\n",
            "Test loss : 82.321861\n",
            "Epoch 62\n",
            "----------------\n",
            "loss : 48.242950, [    0/  354]\n",
            "loss : 57.338287, [  320/  354]\n",
            "Test loss : 82.874577\n",
            "Epoch 63\n",
            "----------------\n",
            "loss : 77.429680, [    0/  354]\n",
            "loss : 109.856682, [  320/  354]\n",
            "Test loss : 82.691943\n",
            "Epoch 64\n",
            "----------------\n",
            "loss : 109.469620, [    0/  354]\n",
            "loss : 56.357254, [  320/  354]\n",
            "Test loss : 82.265218\n",
            "Epoch 65\n",
            "----------------\n",
            "loss : 48.123238, [    0/  354]\n",
            "loss : 87.210449, [  320/  354]\n",
            "Test loss : 81.728840\n",
            "Epoch 66\n",
            "----------------\n",
            "loss : 47.708878, [    0/  354]\n",
            "loss : 81.833107, [  320/  354]\n",
            "Test loss : 81.617080\n",
            "Epoch 67\n",
            "----------------\n",
            "loss : 58.065384, [    0/  354]\n",
            "loss : 111.281792, [  320/  354]\n",
            "Test loss : 81.753523\n",
            "Epoch 68\n",
            "----------------\n",
            "loss : 78.695549, [    0/  354]\n",
            "loss : 80.412590, [  320/  354]\n",
            "Test loss : 81.965762\n",
            "Epoch 69\n",
            "----------------\n",
            "loss : 67.739815, [    0/  354]\n",
            "loss : 51.993969, [  320/  354]\n",
            "Test loss : 82.070404\n",
            "Epoch 70\n",
            "----------------\n",
            "loss : 130.601883, [    0/  354]\n",
            "loss : 112.264153, [  320/  354]\n",
            "Test loss : 82.156856\n",
            "Epoch 71\n",
            "----------------\n",
            "loss : 93.944557, [    0/  354]\n",
            "loss : 37.818100, [  320/  354]\n",
            "Test loss : 82.737666\n",
            "Epoch 72\n",
            "----------------\n",
            "loss : 82.274811, [    0/  354]\n",
            "loss : 109.992905, [  320/  354]\n",
            "Test loss : 82.714597\n",
            "Epoch 73\n",
            "----------------\n",
            "loss : 84.216125, [    0/  354]\n",
            "loss : 49.474876, [  320/  354]\n",
            "Test loss : 81.756545\n",
            "Epoch 74\n",
            "----------------\n",
            "loss : 54.223495, [    0/  354]\n",
            "loss : 105.650604, [  320/  354]\n",
            "Test loss : 81.622490\n",
            "Epoch 75\n",
            "----------------\n",
            "loss : 61.395954, [    0/  354]\n",
            "loss : 92.268265, [  320/  354]\n",
            "Test loss : 81.843319\n",
            "Epoch 76\n",
            "----------------\n",
            "loss : 73.166580, [    0/  354]\n",
            "loss : 69.538933, [  320/  354]\n",
            "Test loss : 81.716501\n",
            "Epoch 77\n",
            "----------------\n",
            "loss : 68.791519, [    0/  354]\n",
            "loss : 69.653320, [  320/  354]\n",
            "Test loss : 81.519583\n",
            "Epoch 78\n",
            "----------------\n",
            "loss : 102.013580, [    0/  354]\n",
            "loss : 38.864021, [  320/  354]\n",
            "Test loss : 80.960744\n",
            "Epoch 79\n",
            "----------------\n",
            "loss : 39.910355, [    0/  354]\n",
            "loss : 87.719421, [  320/  354]\n",
            "Test loss : 81.999233\n",
            "Epoch 80\n",
            "----------------\n",
            "loss : 68.374535, [    0/  354]\n",
            "loss : 82.237595, [  320/  354]\n",
            "Test loss : 82.313132\n",
            "Epoch 81\n",
            "----------------\n",
            "loss : 38.675713, [    0/  354]\n",
            "loss : 128.447906, [  320/  354]\n",
            "Test loss : 80.996044\n",
            "Epoch 82\n",
            "----------------\n",
            "loss : 64.233864, [    0/  354]\n",
            "loss : 75.146477, [  320/  354]\n",
            "Test loss : 81.432038\n",
            "Epoch 83\n",
            "----------------\n",
            "loss : 62.213829, [    0/  354]\n",
            "loss : 51.126106, [  320/  354]\n",
            "Test loss : 81.310783\n",
            "Epoch 84\n",
            "----------------\n",
            "loss : 97.660370, [    0/  354]\n",
            "loss : 55.443192, [  320/  354]\n",
            "Test loss : 81.179270\n",
            "Epoch 85\n",
            "----------------\n",
            "loss : 56.967911, [    0/  354]\n",
            "loss : 125.774734, [  320/  354]\n",
            "Test loss : 81.425401\n",
            "Epoch 86\n",
            "----------------\n",
            "loss : 75.572128, [    0/  354]\n",
            "loss : 65.742439, [  320/  354]\n",
            "Test loss : 81.498222\n",
            "Epoch 87\n",
            "----------------\n",
            "loss : 79.602806, [    0/  354]\n",
            "loss : 67.098495, [  320/  354]\n",
            "Test loss : 81.650219\n",
            "Epoch 88\n",
            "----------------\n",
            "loss : 92.411713, [    0/  354]\n",
            "loss : 60.392838, [  320/  354]\n",
            "Test loss : 81.568388\n",
            "Epoch 89\n",
            "----------------\n",
            "loss : 137.116714, [    0/  354]\n",
            "loss : 58.873890, [  320/  354]\n",
            "Test loss : 83.142574\n",
            "Epoch 90\n",
            "----------------\n",
            "loss : 87.813202, [    0/  354]\n",
            "loss : 75.322968, [  320/  354]\n",
            "Test loss : 81.618311\n",
            "Epoch 91\n",
            "----------------\n",
            "loss : 93.827499, [    0/  354]\n",
            "loss : 75.269203, [  320/  354]\n",
            "Test loss : 81.617730\n",
            "Epoch 92\n",
            "----------------\n",
            "loss : 114.332245, [    0/  354]\n",
            "loss : 70.745422, [  320/  354]\n",
            "Test loss : 85.019291\n",
            "Epoch 93\n",
            "----------------\n",
            "loss : 101.605164, [    0/  354]\n",
            "loss : 104.552338, [  320/  354]\n",
            "Test loss : 82.527501\n",
            "Epoch 94\n",
            "----------------\n",
            "loss : 113.957138, [    0/  354]\n",
            "loss : 44.614628, [  320/  354]\n",
            "Test loss : 82.192709\n",
            "Epoch 95\n",
            "----------------\n",
            "loss : 114.876839, [    0/  354]\n",
            "loss : 64.307877, [  320/  354]\n",
            "Test loss : 82.004937\n",
            "Epoch 96\n",
            "----------------\n",
            "loss : 69.630287, [    0/  354]\n",
            "loss : 129.189453, [  320/  354]\n",
            "Test loss : 82.357691\n",
            "Epoch 97\n",
            "----------------\n",
            "loss : 98.996445, [    0/  354]\n",
            "loss : 80.136963, [  320/  354]\n",
            "Test loss : 82.453633\n",
            "Epoch 98\n",
            "----------------\n",
            "loss : 60.086235, [    0/  354]\n",
            "loss : 104.958145, [  320/  354]\n",
            "Test loss : 82.318765\n",
            "Epoch 99\n",
            "----------------\n",
            "loss : 86.490875, [    0/  354]\n",
            "loss : 92.867622, [  320/  354]\n",
            "Test loss : 82.450302\n",
            "Epoch 100\n",
            "----------------\n",
            "loss : 105.911812, [    0/  354]\n",
            "loss : 63.319324, [  320/  354]\n",
            "Test loss : 82.612349\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_loader,model,loss_fn,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5xmtbi3h95J",
        "outputId": "d152076b-4591-40d8-85c5-8b6452073672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss : 96.113225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-150-72c2c018714e>:10: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  test_loss += loss_fn(pred,y).item()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.11322501715686"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def value_predict(model,dataloader,i):\n",
        "    X,y = dataloader.dataset.__getitem__(i)\n",
        "    X,y = X.to(device), y.to(device)\n",
        "    pred = model(X)\n",
        "    return pred.item(),y.item()\n"
      ],
      "metadata": {
        "id": "7pwSZwX3j0vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_predict(model,test_loader,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UQwC1noke6_",
        "outputId": "ada41e55-8af1-4164-c9e9-28105492fd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22.161277770996094, 34.599998474121094)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(losses),len(val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnm8TpYGmo9U",
        "outputId": "9aa75313-8b7e-46a0-ae30-e403275e70ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    }
  ]
}