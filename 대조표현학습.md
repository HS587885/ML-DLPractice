# Contrastive Representation Learning: A Framework and Review

## Contrastive learning
- Input sample 간의 비교를 통해 학습
- 자가 지도 학습에 사용되는 접근법 중 하나. 사전에 정답을 구축하지 않는 판별 모형
- 데이터 구축 비용 X, 학습 시 용이
- 일반적인 특징 표현
- 새로운 class가 들어와도 대응 가능
- 분류 등 다양한 downstream task에 대해서 신경망을 미세조정

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/f1e2d91a-4937-45bb-9176-c50c2b8dd6e8)

## Contrastive representation learning

### 표현 학습

#### 생성 모형
- 비지도 학습
- Data 구축 비용이 낮음
- 저차원 표현을 학습하는 목적함수가 일반적

#### 판별 모형
- 계산 비용이 적고 학습이 용이
- Labeled data에 의존하기 때문에 data construction cost가 큼
- 지엽적 목적함수


- 대조 학습도 표현 학습을 수행하기 위한 하나의 방법
- Input samples 간의 비교를 통해 표현을 학습
- 학습된 표현 공간 상에서 similar data는 가깝게 그렇지 않은 경우는 멀게 학습
- 여러 입력 쌍에 대해서 유사도를 label로 판별 모형을 학습
- 유사함의 여부는 data 자체로부터 정의(자가 지도 학습이 가능)
- 대조 학습 방법의 경우, 다른 작업을 미세조정할 때에 모형 구조 수정 없이 이루어짐
- 대조 학습은 표현 학습에 있어서 간단하면서도 효과적

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/2a9e8c98-b82c-4dc9-8fad-0c4d6e7c79b9)

## Example : Instance discrimination task
- 신경망이 있을 때, 하나의 표본에서 두 가지의 관점이 생성
- 같은 영상에서 나온(같은 식별자에 위치한) 쌍은 무조건 긍정 쌍(positive pair), 이를 제외한 다른 식별자 내 관점과는 모두 부정

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/fe442d5f-e838-41ab-8ec1-bb1e60f1b916)

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/c78f85be-bc12-4242-9ec5-85c9ecd3d425)

### Data augmentation을 통한 입력 쌍 생성

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/f018d9f7-3d11-4683-aeef-632f32371e8d)

- 같은 영상에서 생성이 된다면 긍정 쌍, 다른 영상에서 나왔다면 부정 쌍(negatvie pair)
- 긍정 쌍을 구성할 때는 원본 영상에서 영상 변형(image transformation)을 적용한 증강된 영상(augmented image)를 생성하여 쌍을 구성

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/85159120-098d-4453-8200-a709fe911d12)

### Generating Representation(Feature selection)
- 입력 영상 쌍을 구성하였다면 해당 영상 쌍으로 표현 학습을 하여야 함. 특징을 추출
- 대조 학습 신경망은 같은 부분을 feature encoder e로 칭하고, e는 아래와 같은 feature vector v를 출력
- $e(.)->v = e(x), v \in R^d$
- Encoder의 구조는 특정되지 않고 어떠한 backbone network든 사용 가능

### Projection head
- Encoder에서 얻은 feature vector v를 더 작은 차원으로 줄임(여러 표현을 결합할 수도 있음,contextualization head)
- InstDisc에서는 2048 차원의 feature vector v를 128 차원의 metric embedding z로 투영(차원 축소)

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/e9470195-7b20-4619-9458-004291901899)


#### Metric embedding
- 대조손실은 기본적은 각 쌍의 유사도를 측정(유사도는 거리, entropy 등)
- 유사도는 지표로 나타낼 수 있음. 이에 손실에 입력으로 들어가는 z를 metric embedding
- Projection head 내에서는 특징 표현 공간에서 행렬 표현 공간으로 투영한 것

### Loss
- 긍정 쌍의 embedding은 가깝게, 부정 쌍은 멀게
- i 번째 입력 쌍에 대한 손실의 일반항

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/64095972-abc1-43c6-ba6f-5654dcb25d2c)

- $z^T_iz'_t$ : 두 vector z, z'의 내적. z'은 z의 변형
- $\tau$ : 초매개변수, 두 vector 간의 내적이 전체 손실에 어느 정도 영향을 미치는지 조절
- 분모의 합은 $z_i$에 대해서 하나의 긍정 쌍과 K개의 부정 쌍에 대해서 계산

### After train
- Projection head는 버리고 encoder만 전이 학습을 위한 특징 추출기로 사용
- 이후의 예측기를 뒤에 결합하여 새로운 작업에 적용할 수 있도록 미세 조정



