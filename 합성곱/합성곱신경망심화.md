# 합성곱 신경망의 심화 이해

## 합성곱 계층의 필요성

![image](https://user-images.githubusercontent.com/80622859/221398448-94ba4f0d-fcc2-4299-a1e4-d83b9874d718.png)


- 사실 영상을 입력으로 하는 것은 전결합 계층으로 하기 힘듦
- 모든 pixel들을 나열해야 => 엄청나게 많은 parameter

## 수학적 표현

- 합성곱 계층은 $C_{in} \times C_{out}$ 번의 합성곱 연산
- 편향은 전결합 계층과 동일하게 하나의 vector

## Padding

![image](https://user-images.githubusercontent.com/80622859/221398699-2bea3afb-49be-4204-ba24-479a7c1b5789.png)

- 합성곱 연산 시, filter의 크기에 따라 영상의 크기가 줄어드는 문제 해결
- 크기가 (2N+1)인 kernel에 대해, 상하좌우 N개의 zero-padding을 해주면 됨

## Stride

- 합성곱 연산에서 kernel을 이동시키는 거리를 stride라고 하며, 이를 크게 하면 출력의 크기가 줄어듬

# GoogLeNet

![image](https://user-images.githubusercontent.com/80622859/221402324-4b124cc9-7df2-4b30-881a-1adffe6943fc.png)

- 신경망을 더욱 더 깊게 만들고자 하는 노력
- "Let's Go Deeper and Deeper"

## Inception module

![image](https://user-images.githubusercontent.com/80622859/221402358-1f4c7bab-a290-429f-9449-cd71c9c266cc.png)

- 다양한 크기의 합성곱 계층을 한 번에 계산
- 다양한 크기의 feature들을 나눠서 학습 
- 연산량을 줄이기 위한 1 x 1 합성곱 계층(Bottleneck)
- 똑같은 수용 영역을 가져가면서 parameter 수 적게

## Bottlenect 구조

![image](https://user-images.githubusercontent.com/80622859/221402452-2a11092a-8999-4571-8ebf-0103dfe9e329.png)

- Receptive field를 유지하면서 parameter의 수와 연산량을 줄임

## 추가 분류기 사용(Auxiliary classifier)

![image](https://user-images.githubusercontent.com/80622859/221402485-e281a0eb-82c5-4b0a-bcf2-bc75372caa22.png)

- 역전파에서 기울기 소실이 발생하는 것을 방지하기 위해, 같은 문제를 여러 단계에서 풀도록
