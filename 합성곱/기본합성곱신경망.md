# 기본적인 합성곱 신경망

## 기본 구조

![image](https://user-images.githubusercontent.com/80622859/221397941-0c61174f-b639-480c-9548-cb54fd74e729.png)

- 합성곱 계층, pooling layer, 활성화 함수, 평탄화, 전결합 계층
- 합성곱 계층에서는 영상의 크기는 그대로이며, 영상의 channel 수가 달라짐
- 합성곱 계층에 의해서 추출된 결과는 공간적인 특징이 있으며 feature map이라고 함
- Filter에 대한 정보가 중요
- 같은 크기의 filter가 영상에서 더 넓은 영역을 cover

## Pooling layer

![image](https://user-images.githubusercontent.com/80622859/221398015-adfcf311-d606-4e99-b439-ebdb465b4d3b.png)


- 여러 화소를 조합하여 하나의 화소로 변환하는 계층
- 영상의 크기가 줄어들고, 정보가 종합
- Max pooling, average pooling

## 평탄화(Flatten)

![image](https://user-images.githubusercontent.com/80622859/221398087-28fb5ccc-a499-49c2-a4b7-bfc2169a36fa.png)

- 입력된 feature map의 모든 화소를 나열하여 하나의 vector로 만드는 것
- 아무 연산이 일어나지 않음. 합성곱 계층과 전결합 계층을 연결

## 전결합 계층(Fully connected layer)

- 최종 출력
- 합성곱 신경망으로 추출한 특징을 입력으로 얕은 신경망을 사용하는 것과 같음
- Ex) 분류의 경우에는 softmax 함수 활용

## Receptive field(수용 영역)

![image](https://user-images.githubusercontent.com/80622859/221398233-292af8bf-06aa-4118-9d5a-698b64e1ea8a.png)

- 같은 크기의 filter여도, pooling에 의해 작아진 feature map에 적용되면 원본 영상에서 차지하는 범위가 넓음
- 초반에는 좁은 부분을 보다가 층을 계속 쌓으면서 더 넓은 범위를 보게 됨(Receptive field가 점점 커지게 됨)

## LeNet-5

![image](https://user-images.githubusercontent.com/80622859/221398274-76f7f8c9-1d42-4ff9-91ab-528bbac1c19a.png)

- 1998년

## VGG-16

![image](https://user-images.githubusercontent.com/80622859/221398294-90cf7c15-bab2-4829-85e1-2a736f90b271.png)

- 2014년

