# 강화 학습(Reinforcement Learning)

## 지도 학습
- 정답이 존재
- Direct feedback
- 예측

## 비지도 학습
- 정답 X
- No feedback
- 숨겨진 구조를 찾음

## 강화 학습

- 결정 과정
- 보상 체계
- 일련의 행동을 학습
- 결정이 옳으면 보상을 줌
- 행동에 대한 규칙을 만들어 감
- 행동 지침을 배움

## 조작적 조건 형성
- Skinner box

1. 배고픈 상태의 쥐를 skinner box에 넣음
2. 이렇게 배고픈 상태로 만드는 것을 박탈이라고 함
3. 쥐는 skinner box 안에서 돌아다니다가 우연히 지렛대를 누르게 됨
4. 지렛대를 누르자 먹이가 나옴
5. 쥐는 다시 상자 안을 돌아다니다가 지렛대를 다시 누르고 먹이가 나오는 것을 봄
6. 위와 같은 과정이 반복되면서 쥐는 지렛대를 누르면 먹이가 나온다는 사실을 학습
- f(지렛대) = 먹이

## 정의
- 어떤 환경 안에서 정의된 agent가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법
- 잘한 행동에 대해 칭찬 받고 잘못한 행동에 대해 벌을 받는 경험을 통해 자신의 지식을 키워나가는 학습법
- 환경이나 정책을 잘 모를 때 유용

## 특성
1. Trial and Error
2. Delayed Reward

## 요소

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/862d7f29-2ad4-46e6-8ec8-88d97ad47018)

- Agent : 행동을 하는 주체. 상태를 관찰, 행동을 선택, 목표지향. 
- 환경(Environment) : Agent를 제외한 나머지. Agent가 이동하는 세계. Agent의 현재 상태 및 행동(입력)을 취하여 보상과 다음 상태(출력)을 반환
- 상태(State) : 현재 상황을 나타내는 정보. Agent가 인식하는 구체적이고 즉각적인 자신의 상황. Agent가 마주하는 특성 장소와 시간이며 즉각적인 구성
- 행동(Action) : 현재 상황에서 agent가 하는 것. Agent가 취할 수 있는 모든 행동. Agent는 수행 가능한 행동의 목록 중에서 앞으로 할 행동을 선택해야 함(이산 공간 행동/연속 공간 행동)
- 보상(Reward ) : 행동의 좋고 나쁨을 알려주는 정보. Agent의 행동에 대한 성공이나 실패를 측정하는 feedback. Agent 행동에 의해 평가된 보상은 즉시 주어질 수도, 지연될 수도 있음
- 정책($\pi$) : Agent가 현재 상태를 기준으로 다음의 행동을 결정하는데 사용하는 전략. Agent는 특정한 상태에서 보상을 최대화할 수 있는 행동을 선택
- 할인율($\gamma$, Discount factor) : 보통 0과 1 사이의 값으로 즉각적으로 주어지는 보상보다는 상대적으로 가치가 낮은 미래의 보상을 만들기 위해 고안. 시간이 길수록 위험도가 높음. 감가상각
- 가치(Value function) : 단기적인 보상인 R과 달리 가치는 장기적인 관점에서의 현재 상태에 할인된 모든 보상들의 기댓값. $V\pi(s)$란 현재의 상태에서 정책에 따른 기대되는 보상

$V\pi(s) = \mathbb{E}[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=_s,\pi]$

- Q-value function(action-value function) : Q-value와 value는 비슷하지만 Q-value는 현재의 상태에서 취하는 행동 a를 고려함. $Q\pi (s,a)$는 정책에 따라 행동 a를 취할 경우 현재의 상태에서 받을 장기적 보상. Q는 상태-행동 쌍을 보상에 사상.

$Q\pi(s,a) = \mathbb{E}[R(s_0,a_0)+\gamma R(s_1,a_1)+\gamma^2 R(s_2,a_2)+...|s_0=s,a_0=a,\pi]$

- Agent가 환경에서 자신의 상태를 관찰
- 그 상태에서 어떠한 기준(가치 함수 : 현재 상태에서 미래에 받을 것이라 기대하는 보상의 합)에 따라 행동을 선택
- 선택한 행동을 환경에서 실행
- 환경으로부터 다음 상태와 보상을 받음
- 보상을 통해 agent가 가진 정보를 수정

## 강화 학습 종류

![image](https://github.com/as9786/ML-DLPratice/assets/80622859/433c0304-9696-4bfc-9743-6672b25c0e94)

- Model : Agent가 관측하는 환경을 modeling 한 것
- Policy based agent: 가치 함수 없이 정책과 모형만으로 구성
- Value based agent : 정책 없이 가치 함수와 모형만으로 구성
- Model based agent/ Model free agent : 모형에 대한 정보 = state transition 정보의 유무
- Actor critic : 정책, 가치 함수, 모형을 모두 사용



  
